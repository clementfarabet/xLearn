--------------------------------------------------------------------------------
-- imageBox: extends image library with a bunch of functions
-- 
-- Authors: BenCorda, ClemFarabet
--------------------------------------------------------------------------------
do
   ----------------------------------------------------------------------
   -- Error messages
   --
   local IMAGE_MISMATCH           = "images not the same size"
   local FILE_NOT_FOUND           = "file not found"
   local IMAGE_FORMAT_INVALID     = "image format invalid"
   local IMAGE_FILE_INCOMPLETE    = "image file incomplete"
   local IMAGE_DIMENSIONS_INVALID = "image dimensions invalid"
   local FILE_WRITE_FAILED        = "file write failed"
   local IMAGE_COMMENT            = "# PPM generated by Lua"


   ----------------------------------------------------------------------
   -- image.loadPPM()    
   -- Read a PPM into Tensor [0,1] pixels
   --
   function image.loadPPM( filePathname, mode )
      local MAXVAL = 255

      local input = io.open( filePathname, "rb" )
      if not input then error( FILE_NOT_FOUND .. ": " .. filePathname ) end

      -- read width, height, maxval
      function readNumber()
         -- skip blanks and comments
         repeat
            local c
            
            -- read chars until non blank
            repeat
               c = input:read( 1 )
               if not c then

                  error( IMAGE_FILE_INCOMPLETE .. ": " .. filePathname )
               end
            until c:match( "%S" )
            local s, e = input:seek( "cur", -1 )
            if not s then error( e .. ": " .. filePathname ) end

            -- if comment-start then read chars until after newline
            -- else exit loop
            if "#" == c then input:read("*l") else break end
         until false

         -- read number
         return input:read( "*n" )
      end

      -- check id
      local s = input:read('*line')
      if "P2" == s then
         if mode and mode ~= 1 then
            error( NOT_IMPLEMENTED )
         end
         local width, height, maxval = readNumber(), readNumber(), readNumber()
         -- skip single blank
         input:seek( "cur", 1 )
         -- read pixels
         tensorLoaded = torch.Tensor(width,height)
         for i = 1,tensorLoaded:storage():size() do
            local c = readNumber()
            if not c then
               error( IMAGE_FILE_INCOMPLETE .. ": " .. filePathname )
            end
            -- rescale to [-1,1]
            if (c > maxval) then c = c - (maxval+1)*2 end
            local channel = c / (MAXVAL+1)
            tensorLoaded:storage()[i] = channel
         end
      elseif 'P6' == s then
         local pos = input:seek()
         local s = input:read('*line')
         -- remove comment
         while string.find(s,"^%s*#") do
            pos = input:seek()
            s = input:read('*line')
         end
         -- go back one line
         input:seek("set",pos)
         local width = input:read('*number')
         local height = input:read('*number')
         local depth = input:read('*number')
         depth = input:read('*number')
         depth = input:read('*number')
         local data = input:read('*all')
         -- read pixels
         local tensorTmp = torch.Tensor(3,width,height)
         if depth == 65535 then
            local small,big,val
            for i = 1,tensorTmp:storage():size() do
               small = string.byte(data,i*2)
               big = string.byte(data,i*2+1)
               val = big*256+small
               -- rescale to [0,1]
               --local channel = val / depth
               tensorTmp:storage()[i] = val--channel
            end
         else
            error( IMAGE_FORMAT_INVALID .. ": " .. filePathname )
         end
         tensorLoaded = torch.Tensor(width,height,3)
         for i = 1,3 do
            tensorLoaded:select(3,i):copy(tensorTmp[i])
         end
      else
         error( IMAGE_FORMAT_INVALID .. ": " .. filePathname )
      end
      input:close()

      return tensorLoaded
   end


   ----------------------------------------------------------------------
   -- image.savePPM()    
   -- Write Tensor [0,1] pixels to a PPM.
   --
   function image.savePPM( filePathname, tensorToSave, mode )

      local MAXVAL = 255

      -- open file
      local output, e = io.open( filePathname, "wb" )
      if not output then error( e .. ": " .. filePathname ) end

      -- write ID and comment
      if not output:write( "P2", "\n", IMAGE_COMMENT, "\n") then
         error( FILE_WRITE_FAILED .. ": " .. filePathname )
      end

      -- write width, height, maxval
      if not output:write( tensorToSave:size()[1],  " ", 
                           tensorToSave:size()[2], "\n", MAXVAL, "\n" ) then
         error( FILE_WRITE_FAILED .. ": " .. filePathname )
      end

      -- write pixels
      for i=1,tensorToSave:storage():size() do
         
         -- clamp to [0,1[
         channel = math.min( math.max( tensorToSave:storage()[i], 0.0 ), 1.0 - 1/(MAXVAL+1) )

         -- quantize
         local quantized = math.floor( (channel * (MAXVAL+1)) + 0.5 )

         -- output as string
         if not output:write( string.format('%s\n', quantized) ) then
            error( FILE_WRITE_FAILED .. ": " .. filePathname )
         end
      end

      output:close()

   end


   ----------------------------------------------------------------------
   -- image.loadPNG()    
   -- Read a PNG into Tensor [0,1] pixels
   --
   image.loadPNG = gfx.loadPNG

   function image.savePNG(filename,x)
      graphics.newimage(x):write_to_png(filename)
   end  


   ----------------------------------------------------------------------
   -- image.loadPNG()    
   -- Read a JPG into Tensor [0,1] pixels
   --
   function image.loadJPG(filename, mode)
      require 'jpeg'
      local MAXVAL = 255
      local a = jpeg.load(filename)
      a:mul(1/MAXVAL)
      if mode and mode == 1 then
         if a:nDimension() == 2 then
            -- all good
         elseif a:size(3) == 3 then
            local b = torch.Tensor(a:size(1), a:size(2))
            image.rgb2y(a,b)
            a = b
         elseif a:size(3) ~= 1 then
            error('<image.loadJPG> image loaded has wrong #chanels')
         end
      elseif mode and mode == 3 then
         if a:size(3) ~= 3 then
            error('<image.loadJPG> image loaded has wrong #chanels')
         end
      end
      return a
   end

   function image.getJPGsize(filename)
      require 'jpeg'
      return jpeg.size(filename)
   end

   ----------------------------------------------------------------------
   -- image.load()    
   -- Read an image into Tensor [0,1] pixels
   -- type is inferred from extension
   --
   function image.load(filename,mode)
      local ext = string.match(filename,'%.(%a+)$')
      local tensor
      if ext == 'jpg' then
         tensor = image.loadJPG(filename,mode)
      elseif ext == 'png' then
         tensor = image.loadPNG(filename,mode)
      elseif ext == 'pnm' or ext == 'pgm' then
         tensor = image.loadPPM(filename,mode)
      else
         tensor = 'unknown image type'
      end
      return tensor
   end


   ----------------------------------------------------------------------
   -- image.save()
   -- Write an image from Tensor [0,1]
   -- type is inferred from extension
   --
   function image.save(filename, x)
      local ext = string.match(filename,'%.(%a+)$')
      if ext == 'jpg' then
         error('# ERROR <image.save()> saveJPG not implemented')
      elseif ext == 'png' then
         image.savePNG(filename,x)
      elseif ext == 'pnm' or ext == 'pgm' then
         image.savePPM(filename,x)
      end
   end


   ----------------------------------------------------------------------
   -- image.display(input, scale=1, title='Image Display')    
   -- display 2D tensor
   --
   function image.display(...)
      -- usage
      local _, input, zoom, min, max, legend, w, wx, wy, w2 = toolBox.unpack(
         {...},
         'image.display',
         'displays a single image, with optional saturation/zoom;\n'
            .. 'if the nb of channels is other than 1 or 3, then image.displayList() is called',
         {arg='image', type='torch.Tensor', help='image, (WxHx1 or WxHx3 or WxH)', req=true},
         {arg='zoom', type='number', help='display zoom', default=1},
         {arg='min', type='number', help='lower-bound for range'},
         {arg='max', type='number', help='upper-bound for range'},
         {arg='legend', type='string', help='legend', default='image.display'},
         {arg='win', type='gfx.Window', help='window descriptor'},
         {arg='win_w', type='number', help='window width', default=1200},
         {arg='win_h', type='number', help='window height', default=700},
         {arg='window', type='gfx.Window', help='window descriptor (same as win, for compatibility)'}
      )

      if input:nDimension() == 2 or input:size(3) == 1 or input:size(3) == 3 then
         -- Rescale range
         local myIn = image.scaleForDisplay{tensor=input, min=min, max=max}

         -- Rescale geometry
         local x = math.min(input:size(1)*zoom,wx)
         local y = math.min(input:size(2)*zoom,wy)
         w = w or w2 or gfx.Window(x,y,legend)

         -- blit
         w:blit(myIn, zoom)
      else 
         -- multichanel image (collection of images/features)
         w = image.displayList{images=input, zoom=zoom, min=min, max=max, window=w, legend=legend}
      end

      return w
   end


   ----------------------------------------------------------------------
   -- image.displayPyramid(input, scale=1, title='Image Display')    
   -- display 2D tensor
   --
   function image.displayPyramid(args) -- pyramid,scale,title,window
      local list = args.pyramid
      local title = args.title or "Image Display"
      local scale = args.scale or 1
      local x = math.min(list[1]:size(1)*scale*1.3,1024)
      local y = math.min(list[1]:size(2)*scale*1.3,768)
      local w = args.window or gfx.Window(x,y,title)
      local posx = 0
      local posy = 0
      for i=1,#list do
         w:blit(list[i], scale,posx,posy)
         posx = posx + list[i]:size(1)*scale
      end
   end


   ----------------------------------------------------------------------
   --- Returns a gaussian kernel.
   -- The default parameters generate that occupies the entire kernel.
   --
   function image.gaussian(...)
      -- process args
      local _, width, sigma, amplitude, normalize, 
      width_x, width_y, sigma_x, sigma_y = toolBox.unpack(
         {...},
         'image.gaussian',
         'returns a 2D gaussian kernel',
         {arg='width', type='number', help='Width and Height of the kernel', default=3},
         {arg='sigma', type='number', help='Sigma (x and y)', default=0.25},
         {arg='amplitude', type='number', help='Amplitute of the gaussian (max value)', default=1},
         {arg='normalize', type='number', help='Normalize kernel (exc Amplitude)', default=false},
         {arg='width_x', type='number', help='Width of the kernel', defaulta='width'},
         {arg='width_y', type='number', help='Height of the kernel', defaulta='width'},
         {arg='sigma_x', type='number', help='Sigma, x', defaulta='sigma'},
         {arg='sigma_y', type='number', help='Sigma, y', defaulta='sigma'}
      )

      -- local vars
      local center_x = math.ceil(width_x/2)
      local center_y = math.ceil(width_y/2)

      -- generate kernel
      local gauss = torch.Tensor(width_x, width_y)
      for i=1,width_x do
         for j=1,width_y do
            gauss[i][j] = amplitude * math.exp(-(math.pow((i-center_x)
                                                       /(sigma_x*width_x),2)/2 
                                              + math.pow((j-center_y)
                                                      /(sigma_y*width_y),2)/2))
         end
      end
      if normalize then
         gauss:div(gauss:sum())
      end
      return gauss
   end

   function image.gaussian1D(...)
      -- process args
      local _, size, sigma, amplitude, normalize
         = toolBox.unpack(
         {...},
         'image.gaussian1D',
         'returns a 1D gaussian kernel',
         {arg='size', type='number', help='size the kernel', default=3},
         {arg='sigma', type='number', help='Sigma', default=0.25},
         {arg='amplitude', type='number', help='Amplitute of the gaussian (max value)', default=1},
         {arg='normalize', type='number', help='Normalize kernel (exc Amplitude)', default=false}
      )

      -- local vars
      local center = math.ceil(size/2)

      -- generate kernel
      local gauss = torch.Tensor(size)
      for i=1,size do
         gauss[i] = amplitude * math.exp(-(math.pow((i-center)
                                                 /(sigma*size),2)/2))
      end
      if normalize then
         gauss:div(gauss:sum())
      end
      return gauss
   end


   ----------------------------------------------------------------------
   --- Returns a Laplacian kernel.
   -- The default parameters generate that occupies the entire kernel.
   --
   function image.laplacian(args)
      -- usage
      if not image.laplacian_usage then
         image.laplacian_usage = 
            toolBox.usage('image.laplacian',
                          'returns a 2D laplacian kernel',
                          nil,
            {arg='amplitude', type='number', help='Amplitute of the laplacian (max value)'},
            {arg='normalize', type='number', help='Normalize kernel (cannot be used with Amplitude)'},
            {arg='width', type='number', help='Width and Height of the kernel'},
            {arg='width_x', type='number', help='Width of the kernel'},
            {arg='width_y', type='number', help='Height of the kernel'},
            {arg='sigma', type='number', help='Sigma (x and y)'},
            {arg='sigma_x', type='number', help='Sigma, x'},
            {arg='sigma_y', type='number', help='Sigma, y'},
            {arg='center', type='number', help='Center of the laplacian'},
            {arg='center_x', type='number', help='Center (x) of the laplacian.'},
            {arg='center_y', type='number', help='Center (y) of the laplacian.'})
      end

      -- parse args
      local args = args or error(image.laplacian_usage)
      local amplitude = args.amplitude or 1
      local normalize = args.normalize or false
      local width_x = args.width_x or args.width or 3
      local width_y = args.width_y or args.width or 3
      local sigma_x = args.sigma_x or args.sigma or 1/6
      local sigma_y = args.sigma_y or args.sigma or 1/6
      local center_x = args.center_x or args.center or math.ceil(width_x/2)
      local center_y = args.center_y or args.center or math.ceil(width_y/2)

      local logauss = torch.Tensor(width_x,width_y)
      for i=1,width_x do
         for j=1,width_y do
            local xsq = math.pow((i-center_x)/(sigma_x*width_x),2)/2
            local ysq = math.pow((j-center_y)/(sigma_y*width_y),2)/2
            local derivCoef = 1 - (xsq + ysq)
            logauss[i][j] = derivCoef * amplitude * math.exp(-(xsq + ysq))
         end
      end
      if normalize then
         logauss:div(logauss:sum())
      end
      return logauss
   end


   ----------------------------------------------------------------------
   -- image.loadVideo()
   -- loads arbitrary videos, using FFMPEG (and a temp jpeg cache)
   -- returns a table (list) of images
   --
   function image.loadVideo(...)
      -- usage
      local _, path, w, h, fps, length, channel, list = toolBox.unpack(
         {...},
         'image.loadVideo',
         'loads a video into a table of tensors:\n'
            .. ' + relies on ffpmeg, which must be installed\n'
            .. ' + creates a local scratch/ to hold jpegs',
         {arg='path', type='string', help='path to video', req=true},
         {arg='width', type='number', help='width', default=500},
         {arg='height', type='number', help='height', default=376},
         {arg='fps', type='number', help='frames per second', default=5},
         {arg='length', type='number', help='length, in seconds', default=5},
         {arg='channel', type='number', help='video channel', default=0},
         {arg='list', type='boolean', help='returns a list of jpg filenames', default=false}
      )

      -- check ffmpeg existence
      local res = toolBox.exec('ffmpeg')
      if res:find('not found') then 
         local c = toolBox.COLORS
         error(c.Red .. 'ffmpeg required, please install it (apt-get install ffmpeg)' .. c.none)
      end

      -- make cache
      local date = os.date():gsub(' ','_')
      local path_cache = paths.concat('scratch',date)
      os.execute('mkdir -p ' .. path_cache)
      os.execute('rm ' .. paths.concat(path_cache,'*.jpg'))

      -- process video
      os.execute('ffmpeg -i ' .. path .. 
                 ' -r ' .. fps .. 
                 ' -t ' .. length ..
                 ' -map 0.' .. channel ..
                 ' -s ' .. w .. 'x' .. h .. 
                 ' -qscale 1' ..
                 ' ' .. paths.concat(path_cache,'frame-%04d.jpg'))

      -- load JPEGs
      local imgs = {}
      local idx = 1
      for file in paths.files(path_cache) do
         if file ~= '.' and file ~= '..' then
            local fname = paths.concat(path_cache,string.format('frame-%04d.jpg',idx))
            if list then
               table.insert(imgs, fname)
            else
               table.insert(imgs, image.load(fname))
            end
            idx = idx + 1
         end
      end

      -- record meta params
      imgs.fps = (fps or 5)

      -- return image
      return imgs
   end


   ----------------------------------------------------------------------
   -- image.playVideo()
   -- plays a video (must have been loaded with loadVideo())
   --
   function image.playVideo(...)
      -- usage
      local _, seq, zoom, loop, fps = toolBox.unpack(
         {...},
         'image.playVideo',
         'plays a video:\n'
            .. ' + video must have been loaded with image.loadVideo()\n'
            .. ' + or else, it must be a list of tensors',
         {arg='seq', type='table', help='list/table of images', req=true},
         {arg='zoom', type='number', help='zoom', default=1},
         {arg='loop', type='boolean', help='loop', default=false},
         {arg='fps', type='number', help='fps [default = given by seq.fps]'}
      )

      -- plays vid
      local p =  qtwidget.newwindow(seq[1]:size(1)*zoom,seq[1]:size(2)*zoom)
      local disp = Displayer()
      local frame = torch.Tensor()
      local pause = 1 / (fps or seq.fps) - 0.03
      while true do
         for i,frameByte in ipairs(seq) do
            frame:resize(frameByte:size(1),frameByte:size(2),frameByte:size(3))
            frame:copy(frameByte)
            disp:show{tensor=frame,painter=p,legend='playing sequence',zoom=zoom}
            if pause and pause>0 then libxlearn.usleep(pause*1e6) end
         end
         if not loop then break end
      end
   end


   ----------------------------------------------------------------------
   -- image.loadVideo3D()
   -- loads arbitrary 3D videos, using FFMPEG (and a temp jpeg cache)
   -- returns a table (list) of pairs of images
   --
   function image.loadVideo3D(...)
      -- usage
      local _, path, w, h, fps, length, shift, list = toolBox.unpack(
         {...},
         'image.loadVideo3D',
         'loads a video into a table of tensors:\n'
            .. ' + relies on ffpmeg, which must be installed\n'
            .. ' + creates a local scratch/ to hold jpegs',
         {arg='path', type='string', help='path to video', req=true},
         {arg='width', type='number', help='width', default=500},
         {arg='height', type='number', help='height', default=376},
         {arg='fps', type='number', help='frames per second', default=5},
         {arg='length', type='number', help='length, in seconds', default=5},
         {arg='realign', type='number', help='realign: left shift right image by N pixels and crop', default=0},
         {arg='list', type='boolean', help='returns a list of jpg filenames', default=false}
      )

      -- load channels separately and merge
      local left = image.loadVideo(path,w,h,fps,length,0,list)
      local right = image.loadVideo(path,w,h,fps,length,2,list)
      local pairs = {fps=left.fps}
      for i = 1,#left do
         pairs[i] = {left[i],right[i]}
      end

      -- optional shit
      if shift and not list then
         for i,pair in ipairs(pairs) do
            if shift > 0 then
               -- shit and crop right channel
               pair[2] = pair[2]:narrow(1,1+shift,pair[2]:size(1)-shift)
               -- crop left channel
               pair[1] = pair[1]:narrow(1,1,pair[1]:size(1)-shift)
            else
               -- shit and crop left channel
               pair[1] = pair[1]:narrow(1,1+shift,pair[1]:size(1)-shift)
               -- crop right channel
               pair[2] = pair[2]:narrow(1,1,pair[2]:size(1)-shift)
            end
         end
      end

      return pairs
   end


   ----------------------------------------------------------------------
   -- image.playVideo3D()
   -- plays a video (must have been loaded with loadVideo3D())
   --
   function image.playVideo3D(...)
      -- usage
      local _, seq, zoom, loop, fps = toolBox.unpack(
         {...},
         'image.playVideo3D',
         'plays a video:\n'
            .. ' + video must have been loaded with image.loadVideo()\n'
            .. ' + or else, it must be a list of pairs of tensors',
         {arg='seq', type='table', help='list/table of images', req=true},
         {arg='zoom', type='number', help='zoom', default=1},
         {arg='loop', type='boolean', help='loop', default=false},
         {arg='fps', type='number', help='fps [default = given by seq.fps]'}
      )

      -- plays vid
      local p =  qtwidget.newwindow(seq[1][1]:size(1)*zoom,seq[1][1]:size(2)*zoom)
      local disp = Displayer()
      local framel = torch.Tensor()
      local framer = torch.Tensor()
      local frame = torch.Tensor()
      local pause = 1 / (fps or seq.fps) - 0.08
      while true do
         for i,frameByte in ipairs(seq) do
            -- left
            framel:resize(frameByte[1]:size(1),frameByte[1]:size(2),frameByte[1]:size(3))
            framel:copy(frameByte[1])
            -- right
            framer:resizeAs(framel)
            framer:copy(frameByte[2])
            -- merged
            frame:resize(frameByte[1]:size(1),frameByte[1]:size(2),3)
            frame:select(3,1):copy(framel:select(3,1))
            frame:select(3,2):copy(framer:select(3,1))
            frame:select(3,3):copy(framer:select(3,1))
            -- disp
            disp:show{tensor=frame,painter=p,legend='playing 3D sequence [left=RED, right=CYAN]',zoom=zoom}
            if pause and pause>0 then libxlearn.usleep(pause*1e6) end
         end
         if not loop then break end
      end
   end


   ----------------------------------------------------------------------
   -- image.lena()
   -- Returns Lena (in all directions)
   --
   function image.lena(w,h)
      -- usage
      if not image.lena_usage then
         image.lena_usage = toolBox.usage('image.lena',
                                          'returns a WxHx3 array loaded with Lena !',
                                          nil,
                                          {type='number', help='width'},
                                          {type='number', help='height'})
      end

      local lena = image.loadPNG(paths.concat(paths.install_lua_path, 'XLearn/lena.png'), 3)
      if w or h then
         if type(w) ~= 'number' or type(h) ~= 'number' then
            error(image.lena_usage)
         end
         local lenaResize = torch.Tensor(w or 512, h or 512, 3)
         image.scale(lena, lenaResize, 'bilinear')
         lena = lenaResize
      end
      return lena
   end


   ----------------------------------------------------------------------
   -- image.gabor()
   -- generates a gabor filer
   --
   function image.gabor(size, sigma, angle, period, ellipse_ratio)
      -- init matrix
      local data = lab.zeros(size,size)

      -- image -> pixel
      period = period * size
      sigma = sigma * size

      -- set params
      local halfsize = math.floor(size/2)
      local sigma_x = sigma
      local sigma_y = sigma/ellipse_ratio

      for y=-halfsize,halfsize do
         for x=-halfsize,halfsize do
            x_angle = x*math.cos(angle) + y*math.sin(angle)
            y_angle = -x*math.sin(angle) + y*math.cos(angle)
            data[x+halfsize+1][y+halfsize+1] 
               = math.exp(-0.5*(x_angle^2/sigma_x^2 + y_angle^2/sigma_y^2))
                 * math.cos(2*math.pi*x_angle/period)
         end
      end
      
      -- return new tensor
      return data
   end



   ----------------------------------------------------------------------
   --- computes an histogram of a given tensor
   --
   function lab.hist(tensor,bins)
      local bins = bins or 10
      local hist = {}
      local ten = torch.Tensor():resizeAs(tensor):copy(tensor)
      local min = ten:min()
      local max = ten:max()
      ten:add(-min):div(max):mul(bins - 1e-6):floor():add(1)
      for i = 1,bins do
         hist[i] = 0
      end
      ten:apply(function (x)
                   hist[x] = hist[x] + 1
                end)

      -- cleanup hist
      local cleanhist = {}
      cleanhist.raw = lab.new(hist)[1]
      local _,mx = lab.max(cleanhist.raw)
      local _,mn = lab.min(cleanhist.raw)
      cleanhist.bins = bins
      cleanhist.binwidth = (max-min)/bins
      for i = 1,bins do
         cleanhist[i] = {}
         cleanhist[i].val = min + (i-0.5)*cleanhist.binwidth
         cleanhist[i].nb = hist[i]
      end
      cleanhist.max = cleanhist[mx[1]]
      cleanhist.min = cleanhist[mn[1]]
      return cleanhist
   end



   ----------------------------------------------------------------------
   -- image.scaleForDisplay()    
   -- rescales an image for display
   -- args: copy (if set to true, tensor is copied, to conserve the original)
   --       min,max (if provided, specify the min and max to use)
   --       tensor (the tensor to scale)
   --
   function image.scaleForDisplay(args)
      local tensor = args.tensor
      local min = args.min
      local max = args.max 
      local inplace = args.inplace or false
      local tensorOut = args.tensorOut or (inplace and tensor) 
         or torch.Tensor(tensor:size()):copy(tensor)

      -- resize
      if args.tensorOut then
         tensorOut:resizeAs(tensor):copy(tensor)
      end

      -- rescale min
      if (min == nil) then
         min = tensorOut:min()
      end
      if (min ~= 0) then tensorOut:add(-min) end

      -- rescale for max
      if (max == nil) then
         max = tensorOut:max()
      else
         max = max - min
      end
      if (max ~= 0) then tensorOut:div(max) end
      
      -- saturate
      libxlearn.saturate(tensorOut)
      
      -- and return
      return tensorOut
   end


   ----------------------------------------------------------------------
   -- image.qtdisplay()    
   -- displays an image in a qt window
   --
   function image.qtdisplay(args)
      toolBox.useQT()
      -- Parse Args
      if (args.tensor == nil) then error 'please provide a tensor' end
      local zoom = args.zoom or 1
      local globalzoom = args.globalzoom or 1
      local offset_x = args.offset_x or 0 
      local offset_y = args.offset_y or 0
      local raw = args.raw or false
      local color = args.color or 'black'
      local painter = args.painter 
         or qtwidget.newwindow(args.tensor:size(1)*zoom*globalzoom,
                               args.tensor:size(2)*zoom*globalzoom,
                               args.legend)
      -- display image
      local inputimg
      if raw then
         inputimg = args.tensor
      else
         inputimg = image.scaleForDisplay(args)
      end
      local qtImg = qtwidget.newimage(inputimg)
      painter:image(offset_x*globalzoom, 
                    offset_y*globalzoom,
                    args.tensor:size(1)*zoom*globalzoom, 
                    args.tensor:size(2)*zoom*globalzoom,
                    qtImg, 
                    0, 0, 
                    args.tensor:size(1), args.tensor:size(2))
      -- print legend
      if (args.legend ~= nil) then
         painter:setcolor(color)
         painter:moveto(offset_x*globalzoom + 3, offset_y*globalzoom-1)
         painter:show(args.legend)
      end
      return painter
   end


   ----------------------------------------------------------------------
   -- image.displayList()    
   -- displays a list of images
   --
   function image.displayList(...)
      -- usage
      local _, images, zoom, min, max, offset_x, offset_y, 
      legend, legends, window, window_w, window_h, window2, font = toolBox.unpack(
         {...},
         'image.displayList',
         'displays a list of images on a 2D grid;\n' ..
            'the list can be given as a Lua table, or as a 3D tensor.',
         {arg='images', type='table | torch.Tensor', help='images', req=true},
         {arg='zoom', type='number', help='display zoom', default=1},
         {arg='min', type='number', help='lower-bound for range'},
         {arg='max', type='number', help='upper-bound for range'},
         {arg='offset_x', type='number', help='horizontal display offset', default=0},
         {arg='offset_y', type='number', help='vertical display offset', default=0},
         {arg='legend', type='string', help='window title', default='image.displayList'},
         {arg='legends', type='string', help='individual legends'},
         {arg='win', type='gfx.Window', help='window descriptor'},
         {arg='win_w', type='number', help='window width', default=1200},
         {arg='win_h', type='number', help='window height', default=700},
         {arg='window', type='gfx.Window', help='window descriptor (same as win, for compat)'},
         {arg='font', type='number', help='font size [default = 10*zoom]'}
      )


      -- create painter
      local painter = window or window2 or gfx.Window(window_w, window_h, legend)

      -- if images are in a tensor form, then create a list
      if type(images) == 'userdata' then
         local limages = {}
         if images:nDimension() == 4 then
            for i = 1,images:size(4) do
               table.insert(limages, images:select(4,i))
            end
         else
            for i = 1,images:size(3) do
               table.insert(limages, images:select(3,i))
            end
         end
         images = limages
      elseif type(images) ~= 'table' then
         error(image.displayList_usage)
      end

      -- helper for legends
      local boldtxt = 
         function (text,x,y)
            local p
            for i=-1,1 do
               for j=-1,1 do
                  p=painter:text(text, x*zoom+i, y*zoom+j, font or 12*zoom)
               end
            end
            p:set('penColor',{0,0,0})
            painter:text(text, x*zoom, y*zoom, font or 12*zoom):set('penColor',{1,1,1})
         end

      -- display images
      local max_height = 0
      painter:batchBegin()
      for i = 1,#images do
         local imageNormed = image.scaleForDisplay{tensor=images[i], 
                                                   min=min, max=max}
         if (offset_x + imageNormed:size(1)*zoom) > window_w then
            offset_x = 0
            offset_y = offset_y + max_height*zoom
            max_height = 0
         end
         painter:blit(imageNormed, zoom, offset_x, offset_y)
         if legends and legends[i] then
            boldtxt(legends[i], offset_x/zoom+5, offset_y/zoom+imageNormed:size(2)-3)
         end
         offset_x = offset_x + imageNormed:size(1)*zoom
         if imageNormed:size(2) > max_height then
            max_height = imageNormed:size(2)
         end
      end
      painter:batchEnd()

      -- return display
      return painter, offset_x, offset_y
   end


   ----------------------------------------------------------------------
   --- Creates a random color mapping
   -- @param nbColor  nb of colors to generate
   -- @param seed     used to generate a different set of colors
   --
   function image.createColorMap(nbColor,seed)
      -- note: the best way of obtaining optimally-spaced
      -- colors is to generate them around the HSV wheel,
      -- by varying the Hue component
      local map = torch.Tensor(nbColor,3)
      local huef = 0
      local satf = 0
      for i = 1,nbColor do         
         -- HSL
         local hue = math.mod(huef,360)
         local sat = math.mod(satf,0.7) + 0.3
         local light = 0.5
         huef = huef + 39
         satf = satf + 1/9
         -- HSL -> RGB
         local c = (1 - math.abs(2*light-1))*sat
         local huep = hue/60
         local x = c*(1-math.abs(math.mod(huep,2)-1))
         local redp
         local greenp
         local bluep
         if huep < 1 then
            redp = c; greenp = x; bluep = 0
         elseif huep < 2 then
            redp = x; greenp = c; bluep = 0            
         elseif huep < 3 then
            redp = 0; greenp = c; bluep = x
         elseif huep < 4 then
            redp = 0; greenp = x; bluep = c
         elseif huep < 5 then
            redp = x; greenp = 0; bluep = c
         else
            redp = c; greenp = 0; bluep = x
         end
         local m = light - c/2
         map[i][1] = redp + m
         map[i][2] = greenp + m
         map[i][3] = bluep + m
      end
      return map
   end


   ----------------------------------------------------------------------
   --- Returns a visualization of a segmentation map
   -- if the image is a X*Y(*N) tensor, then
   -- the seg map should be a X*Y map of integers.
   -- @param image     the source image
   -- @param segMap    the segmentation map
   -- @param colorMap  a color map
   --
   function image.mergeSegmentation(image, segMap, colorMap)
      local imageMerged = torch.Tensor():resizeAs(image):copy(image)
      imageMerged:select(3,1):map(segMap, function(pix, seg) return pix+colorMap[seg][1] end)
      imageMerged:select(3,2):map(segMap, function(pix, seg) return pix+colorMap[seg][2] end)
      imageMerged:select(3,3):map(segMap, function(pix, seg) return pix+colorMap[seg][3] end)
      return imageMerged
   end


   ----------------------------------------------------------------------
   --- the following functions are useful to visualize results from
   -- segmentation
   --
   function image.maxPoolingChannel(input)
      if input:nDimension() ~= 3 then
         error('<image.maxPoolingChannel> input should have 3 dims')
      end
      _,maxMap = lab.max(input,3)
      return maxMap:select(3,1)
   end

   function image.maskToRGB_old(mask, colorMap)
      local rgbmap = lab.zeros(mask:size(1), mask:size(2), 3)
      rgbmap:select(3,1):map(mask, function(rgb, seg) return colorMap[seg][1] end)
      rgbmap:select(3,2):map(mask, function(rgb, seg) return colorMap[seg][2] end)
      rgbmap:select(3,3):map(mask, function(rgb, seg) return colorMap[seg][3] end)
      return rgbmap
   end

   function image.maskToRGB(mask, colorMap, rgbmap)
      rgbmap = rgbmap or lab.zeros(mask:size(1), mask:size(2), 3)
      rgbmap:fill(0)

      -- DEBUG
      --print('colorMap size: ')
      --print(colorMap:size())
      -- print('mask size: ')
      -- print(mask:size())
      --print('rgbmap size: ')
      --print(rgbmap:size())
      --print(colorMap)
      --print(mask)
      -- rgbmap:select(3,1):map(mask, function(rgb, seg) return colorMap[seg][1] end)
      -- rgbmap:select(3,2):map(mask, function(rgb, seg) return colorMap[seg][2] end)
      -- rgbmap:select(3,3):map(mask, function(rgb, seg) return colorMap[seg][3] end)
      
      -- for k = 1,3 do
      -- 	 for i=1,rgbmap:size(1) do
      -- 	    for j = 1, rgbmap:size(2) do
      -- 	       rgbmap[i][j][k] = colorMap[mask[i][j]][k]
      -- 	    end
      -- 	 end
      --       end
      --local copyMask = torch.Tensor():resizeAs(mask):copy(mask)
      --local copyColorMap = torch.Tensor():resizeAs(colorMap):copy(colorMap)
      --libxlearn.image_maskToRGB(copyMask, copyColorMap, rgbmap)
      libxlearn.image_maskToRGB(mask, colorMap, rgbmap)

      return rgbmap
   end

   function image.rescaleSegmentation_old(rgbmask, upsampling, input)
      local upscaled = torch.Tensor():resizeAs(input):zero()
      local startx = math.floor((input:size(1) - rgbmask:size(1)*upsampling)/2)
      local starty = math.floor((input:size(2) - rgbmask:size(2)*upsampling)/2)
      local rescaled = upscaled:narrow(1,startx,rgbmask:size(1)*upsampling):narrow(2,starty,rgbmask:size(2)*upsampling) 
      image.scale(rgbmask, rescaled, 'bilinear')
      return upscaled
   end

   function image.rescaleSegmentation(rgbmask, upsampling, input, upscaled)
      --local upscaled = torch.Tensor():resizeAs(input):zero()
      upscaled:fill(0)
      local startx = math.floor((input:size(1) - rgbmask:size(1)*upsampling)/2)
      local starty = math.floor((input:size(2) - rgbmask:size(2)*upsampling)/2)
      local rescaled = upscaled:narrow(1,startx,rgbmask:size(1)*upsampling):narrow(2,starty,rgbmask:size(2)*upsampling) 
      image.scale(rgbmask, rescaled, 'bilinear')
      return upscaled
   end




   function image.applySegmentation(input, output, upsampling, colorMap, merged, rgbmap, upscaled, result)
      local maxedOutput = image.maxPoolingChannel(output)
      if merged then
         maxedOutput:apply(function (x) return merged[x] end)
      end
      
      if not rgbmap then
	 rgbmap = lab.zeros(output:size(1), output:size(2), 3)
      end
      if not upscaled then
	 upscaled = torch.Tensor():resizeAs(input)
      end
      if not result then
	 result = torch.Tensor():resizeAs(input)
      end


      local rgbmask = image.maskToRGB(maxedOutput, colorMap, rgbmap)
      local scaledmask = image.rescaleSegmentation(rgbmask, upsampling, input, upscaled)
     
      for i=1,3 do
         -- copy grayscale version of the input
         result:select(3,i):copy(input:select(3,2))
      end
      result:add(scaledmask)
      return result,scaledmask
   end

   function image.qtdisplaySegmentation(args)
      -- parse args
      toolBox.useQT()
      local input = args.image or error 'please provide a tensor'
      local classes = args.classes or error 'please provide a list of classes'
      local mergedClasses = args.mergedClasses
      local mask = args.mask or error 'please provide a segmentation mask'
      local upsampling = args.upsampling or 1
      local colormap = args.colorMap or image.createColorMap(#classes)
      local zoom = args.zoom or 1
      local legend = args.legend or 'segmentation'
      local painter = args.painter 
         or qtwidget.newwindow((input:size(1)+140)*zoom, input:size(2)*zoom, legend)
      local rgbmap = args.rgbmap or lab.zeros(mask:size(1), mask:size(2), 3)
      local upscaled = args.upscaled or torch.Tensor():resizeAs(input)

      -- merge mask and image
      local result = args.result or torch.Tensor():resizeAs(input)
      local scaledmask
      if mask:size(1) == input:size(1) and mask:size(2) == input:size(2) then
         result = image.mergeSegmentation(input, mask, colormap)
      else
         result,scaledmask = image.applySegmentation(input, mask, upsampling, 
                                                     colormap, mergedClasses, rgbmap, upscaled, result)
      end

      -- paint tensor
      image.qtdisplay{tensor=result, painter=painter, globalzoom=zoom}

      -- print classes
      painter:setfont(qt.QFont{serif=false,italic=false,size=10*zoom})
      painter:setcolor('black')
      local height = math.floor(input:size(2) / #classes)
      for i,class in ipairs(classes) do
         -- color box
         local color = torch.Tensor(1,1,3):copy(colormap:select(1,i))
         local colorbox = torch.Tensor(40,height,3)
         image.scale(color,colorbox,'simple')
         image.qtdisplay{tensor=colorbox, painter=painter, 
                         globalzoom=zoom, 
                         min = 0, max = colormap:max(),
                         offset_x=input:size(1) + 10,
                         offset_y=height*(i-1)}
         -- class
         local x = (input:size(1) + 60)*zoom
         local y = (i * height - 4)*zoom
         painter:moveto(x,y)
         painter:show(class)
      end
      
      -- for ref
      return result,scaledmask,painter
   end

   function image.qtdisplaySegClasses(args)
      -- args
      toolBox.useQT()
      local height = args.height or 500
      if args.image then height = args.image:size(2) end
      local classes = args.classes or error 'please provide a list of classes'
      local mergedClasses = args.mergedClasses
      local colormap = args.colorMap or image.createColorMap(#classes)
      local zoom = args.zoom or 1
      local legend = args.legend or 'segmentation'
      local painter = args.painter 
         or qtwidget.newwindow(180*zoom, height*zoom, legend)

      -- print classes
      painter:setfont(qt.QFont{serif=false,italic=false,size=10*zoom})
      painter:setcolor('black')
      local height = math.floor(height / #classes)
      for i,class in ipairs(classes) do
         -- color box
         local color = torch.Tensor(1,1,3):copy(colormap:select(1,i))
         local colorbox = torch.Tensor(40,height,3)
         image.scale(color,colorbox,'simple')
         image.qtdisplay{tensor=colorbox, painter=painter, 
                         globalzoom=zoom, 
                         min = 0, max = colormap:max(),
                         offset_x=0,
                         offset_y=height*(i-1)}
         -- class
         local x = 60*zoom
         local y = (i * height - 4)*zoom
         painter:moveto(x,y)
         painter:show(class)
      end
   end


   ----------------------------------------------------------------------
   -- image.qtdrawbox()    
   -- displays a box in a qt window
   --
   function image.qtdrawbox(args)
      toolBox.useQT() 
      if (args.painter == nil) then
         print 'please provide a painter'
         return
      end
      local painter = args.painter
      local globalzoom = args.globalzoom or 1
      local zoom = args.zoom or 1
      local x = args.x or 0 
      local y = args.y or 0
      local w = args.w or 32
      local h = args.h or 32
      local color = args.color or 'red'
      local width = args.linewidth or 1
      local fontsize = args.fontsize or 16

      -- draw a box
      painter:setcolor(color)
      painter:newpath()
      painter:rectangle(x*globalzoom,y*globalzoom,w*globalzoom*zoom,h*globalzoom*zoom)
      painter:closepath()
      painter:setlinewidth(width)
      painter:stroke()
      
      -- and legend
      if args.legend ~= nil then
         painter:setcolor(color)
         painter:setfont(qt.QFont{serif=false,italic=false,size=fontsize})
         painter:moveto(x*globalzoom, y*globalzoom)
         painter:show(args.legend)
      end
   end


   ----------------------------------------------------------------------
   -- image.pad2D()    
   -- pad a 2Dtensor with zeros
   --
   function image.pad2D(input, pad_l, pad_r, pad_t, pad_b)
      -- init matrix
      local pIn = lab.zeros(input:size(1)+pad_l+pad_r,input:size(2)+pad_t+pad_b)
      local vIn = pIn:narrow(1, pad_l+1, input:size(1))
      vIn = vIn:narrow(2, pad_t+1, input:size(2))
      vIn:copy(input)
      return pIn
   end


   ----------------------------------------------------------------------
   -- image.threshold()    
   -- thresholds an image
   --
   function image.threshold(image, threshold, low, mid, high)
      libxlearn.threshold(image, threshold, low, mid, high)
   end


   ----------------------------------------------------------------------
   -- image.lower()    
   -- ??
   --
   function image.lower(image, threshold)
      libxlearn.lower(image, threshold)
   end


   ----------------------------------------------------------------------
   -- image.convolveAndAcc()    
   -- convolves a 2Dtensor with a 2D kernel
   --
   function image.convolveAndAcc(input, kernel, output, mode)
      if (mode == nil or mode == 'valid') then
         local input = input:unfold(1, kernel:size(1), 1)
         input = input:unfold(2, kernel:size(2), 1)
         output:addT4dotT2(1, input, kernel)
         
      elseif (mode == 'same') then
         -- create padded coefficients
         local padH = math.floor(kernel:size(1)/2)
         local padW = math.floor(kernel:size(2)/2)
         local isHPair = kernel:size(1) % 2 == 0
         local isWPair = kernel:size(2) % 2 == 0
         local coef = lab.ones(input:size(1),input:size(2))
         coef = image.pad(coef, padH, padW, isHPair, isWPair)
         coef = image.convolve(coef, kernel, 'valid')
         
         -- compute mean
         local temp = image.pad(input, padH, padW, isHPair, isWPair)
         temp = image.convolve(temp, kernel, 'valid')
         output:addcdiv(1, temp, coef)
      else
         error(toolBox.NOT_IMPLEMENTED)
      end
      return output
   end

   function image.convolve(input, kernel, mode)
      local function convolveSlice(input, kernel, mode)
         local output
         if (mode == nil or mode == 'valid') then
            output = lab.zeros(input:size(1)-kernel:size(1)+1,
                               input:size(2)-kernel:size(2)+1)
         elseif (mode == 'same') then
            output = lab.zeros(input:size())
         end
         return image.convolveAndAcc(input, kernel, output, mode)
      end
      if input:nDimension() == 3 then
         local featMap = input:size(3)
         local output = torch.Tensor()
         repeat
            local features = convolveSlice(input:select(3,featMap), 
                                           kernel, mode)
            output:resize(features:size(1),features:size(2),input:size(3))
            output:select(3,featMap):copy(features)
            featMap = featMap-1
         until featMap <= 0
         return output
      elseif input:nDimension() == 2 then
         return convolveSlice(input, kernel, mode)
      else
         error("image.convolve only handles 2D or 3D tensor")
      end
   end


   ----------------------------------------------------------------------
   -- pad with 0s the 2 first dims of the input
   -- first dim padded with padW on both side
   -- second dim padded with padH on both side
   --
   function image.pad(input, padH, padW, isHPair, isWPair)
      if (input:nDimension()<2) then
         error('input has to have at least 2 Dimensions')
      end
      local outSize = input:size()
      -- handle kernel even size
      local hpair = (isHPair and 1) or 0
      local wpair = (isWPair and 1) or 0
      outSize[1] = outSize[1] + 2*padH - hpair
      outSize[2] = outSize[2] + 2*padW - wpair
      local out = torch.Tensor(outSize):zero()
      out:sub(padH+1,padH+input:size(1),padW+1,padW+input:size(2)):copy(input)
      return out
   end


   ----------------------------------------------------------------------
   --- Processes an image, and returns the local maximas.
   -- Returns a list of results, each entry containing {x,y,class,confidence}
   -- @param tensor        Output of network. Should be 3D.
   -- @param listOfBlobs   Exising list of blobs. Results will be appended.
   -- @param threshold     Threshold for detection.
   -- @param maxsize       Maximum size of blob (unused now).
   -- @param discardClass  Class to ignore. 
   -- @param preprocess    Optional filtering.
   -- @param scale         Scale of the given map
   -- @param labels        Optional labels for classes
   --
   function image.findBlobs(args)
      -- args
      local tensor = args.tensor
      local threshold = args.threshold or 0
      local maxsize = args.maxsize or 20
      local discardClass = args.discardClass or -1
      local preprocess = args.preprocess or image.gaussian{width=3, normalize=true}
      local scale = args.scale or 1
      local labels = args.labels or {}

      -- preprocess image
      if (preprocess) then
         for i=1,tensor:size(3) do
            tensor:select(3,i):copy(image.convolve(tensor:select(3,i),
                                                   preprocess, 'same'))
         end
      end
      
      -- vars
      if (args.listOfBlobs ~= nil) then
         blobs = args.listOfBlobs
      else
         blobs = {}
         blobs.nextBlob = 1
         blobs.nbOfBlobs = 0
      end
      local prevLine = torch.Tensor(tensor:size(1)):fill(-1)
      local currLine = torch.Tensor(tensor:size(1)):fill(-1)
      local pixel
      
      -- a bunch of functions to modify result list
      local function blobGrow(blob,x,y,val,tag)
         if (x < blob.minx) then blob.minx = x end
         if (x > blob.maxx) then blob.maxx = x end
         if (y < blob.miny) then blob.miny = y end
         if (y > blob.maxy) then blob.maxy = y end
         if (val > blob.weight) then
            blob.x = x;
            blob.y = y;
            blob.weight = val;
         end
         blob.tag = tag
      end
      
      local function blobMerge(blob1, blob2)
         blobGrow(blob1,blob2.minx,blob2.miny,-1)
         blobGrow(blob1,blob2.minx,blob2.miny,-1)
         if (blob2.weight > blob1.weight) then
            blob1.x = blob2.x;
            blob1.y = blob2.y;
            blob1.weight = blob2.weight;
         end
      end

      local function blobDelete(blob)
         blobs.nextBlob = blob.id
         blobs[blob.id] = nil
         blobs.nbOfBlobs = blobs.nbOfBlobs - 1
      end

      local function blobAdd()
         -- Find the next available empty slot to add the new blob
         while true do
            if (blobs[blobs.nextBlob] == nil) then
               break
            end
            blobs.nextBlob = blobs.nextBlob + 1
         end
         blobs.nbOfBlobs = blobs.nbOfBlobs + 1

         -- init slot
         blobs[blobs.nextBlob] = {id=blobs.nextBlob}
         blobs[blobs.nextBlob].x = 0;
         blobs[blobs.nextBlob].y = 0;
         blobs[blobs.nextBlob].weight = -1;
         blobs[blobs.nextBlob].maxx = 0;
         blobs[blobs.nextBlob].maxy = 0;
         blobs[blobs.nextBlob].minx = 2^16;
         blobs[blobs.nextBlob].miny = 2^16;
         blobs[blobs.nextBlob].scale = scale;
                  
         -- return next slot
         return blobs[blobs.nextBlob].id
      end

      local function blobPrint(blob)
         print ('blob at ', blob.x, blob.y, ' id = ', blob.id)
      end

      -- find maxs
      -- try to find a local max
      for n=1,tensor:size(3) do
         if (n ~= discardClass) then

            for y=1,tensor:size(2) do
               for x=1,tensor:size(1) do
                  
                  -- reset local max
                  local currentMax = threshold
                  
                  -- threshold
                  pixel = tensor[x][y][n]
                  if pixel > currentMax then

                     -- we're in a blob now
                     local lastBlobId = -1
                     
                     -- connected to existing blob ? -> updating
                     if (x > 1 and prevLine[x-1] > -1) then
                        lastBlobId = prevLine[x-1]
                        blobGrow(blobs[lastBlobId], x, y, pixel, labels[n])
                        currLine[x] = lastBlobId
                     end
                     
                     -- connected to existing blob ? updating
                     if (prevLine[x] > -1) then
                        lastBlobId = prevLine[x];
                        blobGrow(blobs[lastBlobId], x, y, pixel, labels[n])
                        currLine[x] = lastBlobId
                     end
                     

                     if ( (x+1) <= tensor:size(1) and prevLine[x+1] > -1 ) then

                        -- connected to two different blobs ? merging
                        if (lastBlobId > -1) and (prevLine[x+1] ~= lastBlobId)
                        then
                           -- -1-2-  => 1 and 2 need to be merged: connected
                           -- --X--     by X
                           blobMerge(blobs[lastBlobId], blobs[prevLine[x+1]])

                           -- Clear merged blob
                           prevBlob = prevLine[x+1]
                           for tx=x+1,tensor:size(1) do
                              if (prevLine[tx] == prevBlob) then
                                 prevLine[tx] = lastBlobId
                              else
                                 break
                              end
                           end
                           -- Delete merged blob
                           blobDelete(blobs[prevBlob])
                        else
                           -- Connected to existing blob => updating
                           lastBlobId = prevLine[x+1]
                           blobGrow(blobs[lastBlobId], x, y, pixel, labels[n])
                           currLine[x] = lastBlobId
                        end
                     end

                     -- No blob found in the previous line
                     if (x > 1 and currLine[x-1] > -1) then
                        -- Update with previous element in the current line
                        lastBlobId = currLine[x-1]
                        blobGrow(blobs[currLine[x-1]], x, y, pixel, labels[n])
                        currLine[x] = lastBlobId
                     end

                     if (lastBlobId == -1) then
                        -- No blob found, create a new one
                        lastBlobId = blobAdd{}
                        blobGrow(blobs[blobs.nextBlob], x, y, pixel, labels[n])
                        currLine[x] = lastBlobId
                     end
                     
                  else
                     -- Nothing there... set blob id to -1
                     currLine[x] = -1
                  end
                  
               end
               
               -- store the current line for next iteration
               prevLine:copy(currLine)
            end
         end
      end

      return blobs
   end


   ----------------------------------------------------------------------
   --- Rempa blobs using their scale parameter.
   -- The input list should be reordered (call image.reorderBlobs)
   -- @param blobs   Input list of blobs.
   --
   function image.remapBlobs(blobs)
      -- merge similar blobs:
      for i = 1,#blobs do
         blobs[i].x = blobs[i].x / blobs[i].scale
         blobs[i].y = blobs[i].y / blobs[i].scale
      end
      return blobs
   end


   ----------------------------------------------------------------------
   --- Merges close blobs, based on the given distance.
   -- The input list should be reordered (call image.reorderBlobs)
   -- @param blobs      Input list of blobs.
   -- @param distance   Merging distance.
   --
   function image.mergeBlobs(blobs, distance)
      -- nb of blobs
      local nbBlobs = blobs.nbOfBlobs
      
      -- merge similar blobs:
      for i = 1,nbBlobs do
         if blobs[i] ~= nil then
            for j = 1,nbBlobs do
               if (i ~= j) and (blobs[j] ~= nil) 
                            and (math.abs(blobs[i].x - blobs[j].x) < distance) 
                             and (math.abs(blobs[i].y - blobs[j].y) < distance)
                  then
                  blobs[i].x = (blobs[i].x + blobs[j].x) / 2
                  blobs[i].y = (blobs[i].y + blobs[j].y) / 2
                  blobs[i].scale = (blobs[i].scale + blobs[j].scale)/2
                  if blobs[i].weight < blobs[j].weight then
                     blobs[i].tag = blobs[j].tag
                  end
                  blobs[j] = nil
                  blobs.nbOfBlobs = blobs.nbOfBlobs - 1
               end
            end
         end
      end

      -- return reordered list
      return image.reorderBlobs(blobs)
   end


   ----------------------------------------------------------------------
   --- Reorders blobs, to produce a clean table with a correct dimension.
   -- @param blobs      The blob list, as returned by image.findBlobs()
   --
   function image.reorderBlobs(blobs)
      local reordered = {}
      local processed = 0
      local ordered = 0
      while true do
         if (blobs[processed] ~= nil) then
            ordered = ordered + 1
            reordered[ordered] = {}
            reordered[ordered].x = blobs[processed].x
            reordered[ordered].y = blobs[processed].y
            reordered[ordered].scale = blobs[processed].scale
            reordered[ordered].tag = blobs[processed].tag
            reordered[ordered].weight = blobs[processed].weight
         end
         if (ordered == blobs.nbOfBlobs) then break end
         processed = processed + 1
      end
      reordered.nbOfBlobs = #reordered
      return reordered
   end


   ----------------------------------------------------------------------
   --- Estimate speed of blobs
   -- The input lists should be reordered (call image.reorderBlobs)
   -- @param currentBlobs      Current list of blobs.
   -- @param previousBlobs     Previous list of blobs.
   -- @param timeDelta         Time between two lists
   -- @param distance          Max possible motion distance.
   --
   function image.getSpeed(currentBlobs, previousBlobs, timeDelta, distance)
      -- output
      local speedList = {}

      -- compute speed:
      for i = 1,#currentBlobs do
         speedList[i] = {}
         speedList[i].x = 0.0
         speedList[i].y = 0.0
         for j = 1,#previousBlobs do
            if (math.abs(currentBlobs[i].x - previousBlobs[j].x) < distance) 
            and  
            (math.abs(currentBlobs[i].y - previousBlobs[j].y) < distance) then
            speedList[i].x = (currentBlobs[i].x - previousBlobs[j].x) / timeDelta
            speedList[i].y = (currentBlobs[i].y - previousBlobs[j].y) / timeDelta
            end
         end
      end

      -- return reordered list
      return speedList
   end


   ----------------------------------------------------------------------
   --- Estimate next positions
   -- The input lists should be reordered (call image.reorderBlobs)
   -- @param currentBlobs      Current list of blobs.
   -- @param previousBlobs     Previous list of blobs.
   -- @param timeDelta         Time between two lists
   -- @param distance          Max possible motion distance.
   --
   function image.getNextPos(blobs, speeds, timeDelta)
      -- output
      local nextPos = {}

      -- compute speed:
      for i = 1,#blobs do
         nextPos[i] = {}
         nextPos[i].x = blobs[i].x + speeds[i].x*timeDelta
         nextPos[i].y = blobs[i].y + speeds[i].y*timeDelta
         nextPos[i].scale = blobs[i].scale
         nextPos[i].tag = blobs[i].tag
         nextPos[i].weight = blobs[i].weight
      end

      -- return reordered list
      return nextPos
   end


   ----------------------------------------------------------------------
   --- Creates a pyramid of images (gaussian)
   -- @param tensor   input image
   -- @param scales   a list of scales to be generated
   -- @param minSize  the minimum size to generate
   --
   function image.makePyramid(...)
      -- process args
      local _, tensor, scales, ratio, minSize = toolBox.unpack(
         {...},
         'image.makePyramid',
         'creates a pyramid out of a 2/3/4D tensor',
         {arg='tensor', type='torch.Tensor', help='input tensor, must be 2D, 3D or 4D', req=true},
         {arg='scales', type='table', help='a list of scales is used)'},
         {arg='ratio', type='table', help='if scales not provided, ratio is used to autogen scales',
                       default=1/math.sqrt(2)},
         {arg='min_size', type='number', help='minimum size after rescaling', default=5}
      )

      -- create pyramid
      local create 
         = function(tensor)
              local result = {}
              local idx = 1
              local dimx = tensor:size(1)
              local dimy = tensor:size(2)
              local dimz = tensor:size(3)
              local temp = torch.Tensor():resizeAs(tensor):copy(tensor)
              repeat
                 -- compute reduce size
                 if scales then
                    if not scales[idx] then break end
                    if scales[idx] == 1 then
                       table.insert(result, torch.Tensor():resizeAs(temp):copy(temp))
                       idx = idx + 1
                    end
                    dimx = math.floor(tensor:size(1)*scales[idx])
                    dimy = math.floor(tensor:size(2)*scales[idx])
                 else
                    if idx == 1 then 
                       table.insert(result, torch.Tensor():resizeAs(temp):copy(temp))
                    end
                    dimx = math.floor(dimx*ratio)
                    dimy = math.floor(dimy*ratio)
                 end
                 if dimx<minSize or dimy<minSize then break end
                 -- resize
                 local res = torch.Tensor(dimx,dimy,dimz)
                 image.scale(temp, res, 'bilinear')
                 -- save
                 table.insert(result, res)
                 idx = idx + 1
              until false
              return result
           end

      -- if 4D, assume a list of 3D images
      local result
      if tensor:nDimension() == 4 then
         result = {}
         for i = 1,tensor:size(4) do
            local slice = tensor:select(4,i)
            table.insert(result, create(slice))
         end
      else
         -- 3D or 2D, plain images
         result =  create(tensor)
      end

      -- done
      return result
   end


   ----------------------------------------------------------------------
   -- image.displayVideo(file)
   -- just displays a video...
   --
   function image.displayVideo(file)
      require 'libmpeg2'

      -- Create decoder
      local decoder = mpeg2.Decoder(file,'s',0)
      local x = torch.Tensor(20,20) -- needs some dims to start, else segfault

      -- Display video
      local w = gfx.Window(640,480, 'Video Decoding')
      while decoder:newFrame(x)~=0 do
         image.display(x, 2, nil, nil, w)
      end
   end


   ----------------------------------------------------------------------
   -- image.rgb2yuv(image)
   -- converts a RGB image to YUV
   --
   function image.rgb2yuv(input, ...)
      local arg = {...}
      local output = arg[1] or torch.Tensor()

      -- resize
      output:resizeAs(input)

      -- input chanels
      local inputRed = input:select(3,1,1)
      local inputGreen = input:select(3,2,1)
      local inputBlue = input:select(3,3,1)

      -- output chanels
      local outputY = output:select(3,1,1)
      local outputU = output:select(3,2,1)
      local outputV = output:select(3,3,1)

      -- convert
      outputY:copy( inputRed*0.299 + inputGreen*0.587 + inputBlue*0.114 )
      outputU:copy( inputRed*(-0.14713) 
                    + inputGreen*(-0.28886) 
                    + inputBlue*0.436 )
      outputV:copy( inputRed*0.615 
                    + inputGreen*(-0.51499) 
                    + inputBlue*(-0.10001) )
      
      -- return YUV image
      return output
   end


   ----------------------------------------------------------------------
   -- image.yuv2rgb(image)
   -- converts a YUV image to RGB
   --
   function image.yuv2rgb(input, ...)
      local arg = {...}
      local output = arg[1] or torch.Tensor()

      -- resize
      output:resizeAs(input)
      
      -- input chanels
      local inputY = input:select(3,1,1)
      local inputU = input:select(3,2,1)
      local inputV = input:select(3,3,1)

      -- output chanels
      local outputRed = output:select(3,1,1)
      local outputGreen = output:select(3,2,1)
      local outputBlue = output:select(3,3,1)

      -- convert
      outputRed:copy(inputY):add(1.13983, inputV)
      outputGreen:copy(inputY):add(-0.39465, inputU):add(-0.58060, inputV)      
      outputBlue:copy(inputY):add(2.03211, inputU)
      
      -- return RGB image
      return output
   end


   ----------------------------------------------------------------------
   -- image.rgb2y(image)
   -- converts a RGB image to Y (discards U/V)
   --
   function image.rgb2y(input, ...)
      local arg = {...}
      local output = arg[1] or torch.Tensor()
      
      -- resize
      output:resize(input:size(1), input:size(2), 1)

      -- input chanels
      local inputRed = input:select(3,1,1)
      local inputGreen = input:select(3,2,1)
      local inputBlue = input:select(3,3,1)

      -- output chanels
      local outputY = output:select(3,1,1)

      -- convert
      outputY:zero():add(0.299, inputRed):add(0.587, inputGreen):add(0.114, inputBlue)

      -- return YUV image
      return output
   end


   ----------------------------------------------------------------------
   -- image.rgb2hsl(image)
   -- converts an RGB image to HSL
   --
   function image.rgb2hsl(input, ...)
      local arg = {...}
      local output = arg[1] or torch.Tensor()

      -- resize and compute
      output:resizeAs(input)
      libxlearn.rgb2hsl(input,output)

      -- return HSL image
      return output
   end


   ----------------------------------------------------------------------
   -- image.hsl2rgb(image)
   -- converts an HSL image to RGB
   --
   function image.hsl2rgb(input, ...)
      local arg = {...}
      local output = arg[1] or torch.Tensor()

      -- resize and compute
      output:resizeAs(input)
      libxlearn.hsl2rgb(input,output)

      -- return HSL image
      return output
   end


   ----------------------------------------------------------------------
   -- image.rgb2hsv(image)
   -- converts an RGB image to HSV
   --
   function image.rgb2hsv(input, ...)
      local arg = {...}
      local output = arg[1] or torch.Tensor()

      -- resize and compute
      output:resizeAs(input)
      libxlearn.rgb2hsv(input,output)

      -- return HSV image
      return output
   end


   ----------------------------------------------------------------------
   -- image.hsv2rgb(image)
   -- converts an HSV image to RGB
   --
   function image.hsv2rgb(input, ...)
      local arg = {...}
      local output = arg[1] or torch.Tensor()

      -- resize and compute
      output:resizeAs(input)
      libxlearn.hsv2rgb(input,output)

      -- return HSV image
      return output
   end


   ----------------------------------------------------------------------
   -- image.test_conversions(image)
   -- tests/validates conversions
   --
   function image.test_conversions()
      print('+++ testing image conversions +++')

      -- test 1
      local rgb = image.lena()
      local res = image.hsl2rgb(image.rgb2hsl(rgb))
      local err = (rgb-res):abs():max()
      print('RGB->HSL->RGB: max error = ' .. err)

      -- test 2
      res = image.hsv2rgb(image.rgb2hsv(rgb))
      err = (rgb-res):abs():max()
      print('RGB->HSV->RGB: max error = ' .. err)

      -- test 3
      res = image.yuv2rgb(image.rgb2yuv(rgb))
      err = (rgb-res):abs():max()
      print('RGB->YUV->RGB: max error = ' .. err)

      print('--- testing done ---')
   end


   ----------------------------------------------------------------------
   -- image.yuv2file(image) and image.file2yuv(image)
   -- The U and V chanels contain negative numbers, and these two functions map
   -- and unmap these ranges to [0,1], for file saving.
   --
   function image.yuv2file(input)
      local output = torch.Tensor():resizeAs(input)

      -- input chanels
      local inputY = input:select(3,1,1)
      local inputU = input:select(3,2,1)
      local inputV = input:select(3,3,1)

      -- output chanels
      local outputY = output:select(3,1,1)
      local outputU = output:select(3,2,1)
      local outputV = output:select(3,3,1)

      -- convert
      outputY:copy( inputY )
      outputU:copy( (inputU/(0.436*2)) + 0.5 )
      outputV:copy( (inputV/(0.615*2)) + 0.5 )
      
      -- return RGB image
      return output
   end

   function image.file2yuv(input)
      local output = torch.Tensor():resizeAs(input)

      -- input chanels
      local inputY = input:select(3,1,1)
      local inputU = input:select(3,2,1)
      local inputV = input:select(3,3,1)

      -- output chanels
      local outputY = output:select(3,1,1)
      local outputU = output:select(3,2,1)
      local outputV = output:select(3,3,1)

      -- convert
      outputY:copy( inputY )
      outputU:copy( (inputU - 0.5)*0.436*2 )
      outputV:copy( (inputV - 0.5)*0.615*2 )
      
      -- return RGB image
      return output
   end


   ----------------------------------------------------------------------
   -- image.displayNetwork{painter,network,maps,filters,globalzoom,legend}
   -- displays the internals of a network
   --
   function image.displayNetwork(args)
      toolBox.useQT()
      -- parse args
      if (args.network == nil) then error 'please provide a network' end
      local network = args.network
      local dumpfile = args.dumpfile or nil
      local legend = args.legend or 'Network'
      local dispMaps = args.maps or false
      local dispFilters = args.filters or false
      local globalzoom = args.globalzoom or 1
      local filterzoom = args.filterzoom or 8
      local input = args.input or nil
      local painter = args.painter or nil 
      if painter == nil and dumpfile ~= nil then
         print('# Dumping network internals to file')
         painter = qtwidget.newimage(4000,3000)
      elseif painter == nil then
         print('# Displaying network internals')
         painter = qtwidget.newwindow(1600,1200,legend)
      end
      
      -- font
      local fontHeight = 20
      painter:setfont(qt.QFont{serif=false,italic=false,size=fontHeight*globalzoom})

      -- print pointers
      local current_x = 0
      local current_y = fontHeight*2

      -- optional forward
      if input ~= nil then
         network:forward(input)
         -- display legend
         painter:moveto(current_x*globalzoom + 3, current_y*globalzoom-1)
         painter:show('input')
         -- disp input
         if dispMaps ~= nil then
            image.qtdisplay{painter=painter, tensor=input,
                            globalzoom=globalzoom,
                            offset_x=current_x, offset_y=current_y}
            current_x = current_x + input:size(1)
            current_y = fontHeight*2
         end
      end
      
      -- display network
      for i=1,#network.modules do
         local module = network.modules[i]
         local name = module.__typename

         -- display filters
         if name == 'nn.SpatialConvolution' then
            if dispFilters == true then
               current_x = current_x + module.weight:size(1)*filterzoom
               current_y = fontHeight*2
               painter:moveto(current_x*globalzoom + 3, current_y*globalzoom-1)
               painter:show('ker')
               for i = 1,module.weight:size(4) do
                  image.qtdisplay{painter=painter, tensor=module.weight:select(4,i,1),
                                  globalzoom=globalzoom,
                                  zoom=filterzoom,
                                  offset_x=current_x, offset_y=current_y}
                  current_y = current_y + module.weight:size(2)*filterzoom + 2
               end
               current_x = current_x + module.weight:size(1)*filterzoom*2
               current_y = fontHeight*2
            end
         elseif name == 'nn.SpatialConvolutionTable' then
            if dispFilters == true then
               current_x = current_x + module.weight:size(1)*filterzoom
               current_y = fontHeight*2
               painter:moveto(current_x*globalzoom + 3, current_y*globalzoom-1)
               painter:show('ker')
               for i = 1,module.weight:size(3) do
                  image.qtdisplay{painter=painter, tensor=module.weight:select(3,i,1),
                                  globalzoom=globalzoom,
                                  zoom=filterzoom,
                                  offset_x=current_x, offset_y=current_y}
                  current_y = current_y + module.weight:size(2)*filterzoom + 2
               end
               current_x = current_x + module.weight:size(1)*filterzoom*2
               current_y = fontHeight*2
            end
         end
         
         -- display maps
         painter:moveto(current_x*globalzoom + 3, current_y*globalzoom-1)
         painter:show(name)
         if dispMaps == true then
            for i = 1,module.output:size(3) do
               local map = module.output:select(3,i,1)
               image.qtdisplay{painter=painter, tensor=map,
                               globalzoom=globalzoom,
                               offset_x=current_x, offset_y=current_y,
                               min=-1, max=1}
               current_y = current_y + map:size(2)
            end
            current_x = current_x + module.output:size(1)
            current_y = fontHeight*2
         end
      end

      -- dump to file
      if dumpfile ~= nil then
         painter:image():save(dumpfile)
      end
   end
end -- global do for local var purpose
